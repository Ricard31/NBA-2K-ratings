{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Get_data_2k_plus_stats.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrEhVKiMpIi6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "import re\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from google.colab import files\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dx5511tIpPvs",
        "colab_type": "text"
      },
      "source": [
        "# 2k ratings data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_QQnW7HpXBb",
        "colab_type": "code",
        "outputId": "0af0644a-f640-4ee9-c85c-bd37baf98ad5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# base URL of the site\n",
        "url=\"https://nba2k19.2kratings.com\"\n",
        "\n",
        "\n",
        "# robots.txt\n",
        "\n",
        "def check_robots_txt(url):\n",
        "  url_robots = url + '/robots.txt'\n",
        "  page = requests.get(url_robots)\n",
        "  soup = BeautifulSoup(page.content, 'lxml')\n",
        "  print(soup.prettify())\n",
        "  \n",
        "  \n",
        "check_robots_txt(url) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<html>\n",
            " <body>\n",
            "  <p>\n",
            "   User-Agent: *\n",
            "Disallow: /wp-admin/\n",
            "Sitemap: https://nba2k19.2kratings.com/page-sitemap.xml\n",
            "Sitemap: https://nba2k19.2kratings.com/team-sitemap.xml\n",
            "Sitemap: https://nba2k19.2kratings.com/player-sitemap1.xml\n",
            "Sitemap: https://nba2k19.2kratings.com/player-sitemap2.xml\n",
            "Sitemap: https://nba2k19.2kratings.com/player-sitemap3.xml\n",
            "Crawl-delay: 10\n",
            "  </p>\n",
            " </body>\n",
            "</html>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urYCjFcbpe5u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# modify the function to add the results to an existing df\n",
        "\n",
        "def get_data(url):\n",
        "  \n",
        "  # request to the page\n",
        "  page = requests.get(url)\n",
        "  soup = BeautifulSoup(page.content, 'lxml')\n",
        "  \n",
        "  \n",
        "  \n",
        "  # get the data for each player in the table\n",
        "  \n",
        "  # table containing all players\n",
        "  table = soup.find(\"tbody\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  for player in table.find_all(\"tr\"):\n",
        "\n",
        "    # name of the player\n",
        "    name = player.find_all(\"td\")[1].a.text\n",
        "    names.append(name)\n",
        "\n",
        "    # name of the team\n",
        "    teams.append(dict_team_url[url])\n",
        "    \n",
        "#     team = player.find_all(\"td\")[1].small.text\n",
        "#     teams.append(team)\n",
        "\n",
        "    # pos\n",
        "    pos = player.find_all(\"td\")[3].text\n",
        "    positions.append(pos)\n",
        "\n",
        "    # height\n",
        "    height =  player.find_all(\"td\")[4].text\n",
        "    heights.append(height)\n",
        "\n",
        "    # rating\n",
        "    rating = player.find_all(\"td\")[2].span.text\n",
        "    ratings.append(rating)\n",
        "\n",
        "    # brand\n",
        "    brand = player.find_all(\"td\")[5].text\n",
        "    brands.append(brand)\n",
        "\n",
        "\n",
        "    # check if all star \n",
        "    if len(player.find_all(\"td\")[1].find_all(\"i\", {\"class\": \"fa fa-star\"})) > 0:\n",
        "      all_star = 1\n",
        "    else: \n",
        "      all_star = 0\n",
        "    all_stars.append(all_star)\n",
        "\n",
        "    # check if injured\n",
        "    if len(player.find_all(\"td\")[1].find_all(\"i\", {\"class\": \"fa fa-plus-circle\"})) > 0:\n",
        "      injured = 1\n",
        "    else: \n",
        "      injured = 0\n",
        "    injury.append(injured)\n",
        "\n",
        "    # check if two-way\n",
        "    if len(player.find_all(\"td\")[1].find_all(\"i\", {\"class\": \"fa fa-arrows-h\"})) > 0:\n",
        "      two_way = 1\n",
        "    else: \n",
        "      two_way = 0\n",
        "    two_ways.append(two_way)\n",
        "\n",
        "\n",
        "    # check if rookie\n",
        "    if len(player.find_all(\"td\")[1].find_all(\"small\")) == 1:\n",
        "      rookie = 1\n",
        "    else:\n",
        "      rookie = 0\n",
        "    rookies.append(rookie)    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R79R1idbphvL",
        "colab_type": "code",
        "outputId": "34cad3e5-c1f4-4920-c879-7ccb2d50ade4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#start getting  list of the url where we can obtain all the data: one URL per team\n",
        "url = 'https://nba2k19.2kratings.com/current-teams-on-nba-2k19'\n",
        "\n",
        "\n",
        "\n",
        "# request to the page\n",
        "page = requests.get(url)\n",
        "soup = BeautifulSoup(page.content, 'lxml')\n",
        "\n",
        "teams = soup.find(\"ul\", {\"class\": \"list-group\"})\n",
        "\n",
        "url_teams = []\n",
        "team_list = []\n",
        "\n",
        "for team in teams.find_all('li'):\n",
        "  url_teams.append(team.a['href'])\n",
        "  team_list.append(team.a.text)\n",
        "  \n",
        "\n",
        "\n",
        "dict_team_url = {url_teams[i]:team_list[i] for i in range(0, len(team_list))}\n",
        "\n",
        "print(dict_team_url)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'https://nba2k19.2kratings.com/team/atlanta-hawks': 'Atlanta Hawks', 'https://nba2k19.2kratings.com/team/boston-celtics': 'Boston Celtics', 'https://nba2k19.2kratings.com/team/brooklyn-nets': 'Brooklyn Nets', 'https://nba2k19.2kratings.com/team/charlotte-hornets': 'Charlotte Hornets', 'https://nba2k19.2kratings.com/team/chicago-bulls': 'Chicago Bulls', 'https://nba2k19.2kratings.com/team/cleveland-cavaliers': 'Cleveland Cavaliers', 'https://nba2k19.2kratings.com/team/dallas-mavericks': 'Dallas Mavericks', 'https://nba2k19.2kratings.com/team/denver-nuggets': 'Denver Nuggets', 'https://nba2k19.2kratings.com/team/detroit-pistons': 'Detroit Pistons', 'https://nba2k19.2kratings.com/team/golden-state-warriors': 'Golden State Warriors', 'https://nba2k19.2kratings.com/team/houston-rockets': 'Houston Rockets', 'https://nba2k19.2kratings.com/team/indiana-pacers': 'Indiana Pacers', 'https://nba2k19.2kratings.com/team/los-angeles-clippers': 'Los Angeles Clippers', 'https://nba2k19.2kratings.com/team/los-angeles-lakers': 'Los Angeles Lakers', 'https://nba2k19.2kratings.com/team/memphis-grizzlies': 'Memphis Grizzlies', 'https://nba2k19.2kratings.com/team/miami-heat': 'Miami Heat', 'https://nba2k19.2kratings.com/team/milwaukee-bucks': 'Milwaukee Bucks', 'https://nba2k19.2kratings.com/team/minnesota-timberwolves': 'Minnesota Timberwolves', 'https://nba2k19.2kratings.com/team/new-orleans-pelicans': 'New Orleans Pelicans', 'https://nba2k19.2kratings.com/team/new-york-knicks': 'New York Knicks', 'https://nba2k19.2kratings.com/team/oklahoma-city-thunder': 'Oklahoma City Thunder', 'https://nba2k19.2kratings.com/team/orlando-magic': 'Orlando Magic', 'https://nba2k19.2kratings.com/team/philadelphia-76ers': 'Philadelphia 76ers', 'https://nba2k19.2kratings.com/team/phoenix-suns': 'Phoenix Suns', 'https://nba2k19.2kratings.com/team/portland-trail-blazers': 'Portland Trail Blazers', 'https://nba2k19.2kratings.com/team/sacramento-kings': 'Sacramento Kings', 'https://nba2k19.2kratings.com/team/san-antonio-spurs': 'San Antonio Spurs', 'https://nba2k19.2kratings.com/team/utah-jazz': 'Utah Jazz', 'https://nba2k19.2kratings.com/team/toronto-raptors': 'Toronto Raptors', 'https://nba2k19.2kratings.com/team/washington-wizards': 'Washington Wizards'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hor782PUpjY8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "names = []\n",
        "teams = []\n",
        "positions = []\n",
        "heights = []\n",
        "ratings = []\n",
        "brands = []\n",
        "injury = []\n",
        "two_ways = []\n",
        "all_stars = []\n",
        "rookies = []\n",
        "\n",
        "for url in url_teams:\n",
        "  get_data(url)\n",
        "  \n",
        "# create dataframe\n",
        "ratings_19 = pd.DataFrame({'name': names, 'team': teams, 'position': positions, \n",
        "              'height' : heights, 'brand' : brands,\n",
        "              'all_star': all_stars, 'injured' : injury, 'two_way' : two_ways, 'rookie': rookies,  'rating': ratings})  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_2A1ydEp-rH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creamos el fichero\n",
        "ratings_19.to_csv(\"2k19_ratings.csv\", index=False)\n",
        "\n",
        "# descargamos en formato .csv\n",
        "files.download(\"2k19_ratings.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPPK2QuSsZEN",
        "colab_type": "text"
      },
      "source": [
        "# Stats data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lukP7u-up_B6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# base URL of the site\n",
        "url=\"https://www.basketball-reference.com\"\n",
        "\n",
        "\n",
        "# robots.txt\n",
        "check_robots_txt(url) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWVitTy9skiz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_stats(url):\n",
        "  page = requests.get(url)\n",
        "  soup = BeautifulSoup(page.content, 'lxml')\n",
        "\n",
        "\n",
        "  col_names = []\n",
        "  for i in range(1,len(soup.tbody.find_all('tr')[1].find_all('td'))+1):\n",
        "        col_names.append(soup.thead.find_all('th')[i].text.replace('%','.pct'))\n",
        "\n",
        "  players = soup.tbody.find_all('tr')\n",
        "  stats_df = pd.DataFrame(np.zeros((0,len(soup.tbody.find_all('tr')[1].find_all('td')))))\n",
        "\n",
        "  # loop through the players\n",
        "  for player in players:\n",
        "\n",
        "    if player['class'] != ['thead']:\n",
        "\n",
        "      # create list for every player\n",
        "      player_as_list = []\n",
        "\n",
        "      #loop through the player's stats\n",
        "      for col in range(0,len(soup.tbody.find_all('tr')[1].find_all('td'))):\n",
        "        player_as_list.append(player.find_all('td')[col].text)\n",
        "\n",
        "      # obtain dataframe  \n",
        "      df = pd.DataFrame(player_as_list)\n",
        "      # append to the whole dataframe; transposed\n",
        "      stats_df = stats_df.append(df.T)\n",
        "\n",
        "  # modify column names and index\n",
        "  stats_df.columns=col_names\n",
        "  stats_df.index = np.arange(len(stats_df))\n",
        "  \n",
        "  # change blank spaces for NAs:\n",
        "  stats_df = stats_df.replace(r'^\\s*$', np.nan, regex=True)\n",
        "  \n",
        "  return stats_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cCkrxcrsbta",
        "colab_type": "text"
      },
      "source": [
        "## Per Game stats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywt19f8Hsmoz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stats_1718 = get_stats('https://www.basketball-reference.com/leagues/NBA_2018_per_game.html')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBbZ3Bz4sogj",
        "colab_type": "text"
      },
      "source": [
        "## Advanced stats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcG7OWAzsqS7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stats_1718_adv = get_stats('https://www.basketball-reference.com/leagues/NBA_2018_advanced.html')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArMZz_dGsuFm",
        "colab_type": "text"
      },
      "source": [
        "## Full stats: per game plus advanced"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdYsuaGCswxi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stats_1718_full = pd.merge(stats_1718, stats_1718_adv, how='inner', on=[\"Player\", 'Pos', 'Age', 'Tm', 'G'])\n",
        "\n",
        "stats_1718_full.columns = ['Player', 'Pos', 'Age', 'Tm', 'G', 'GS', 'MPG', 'FG', 'FGA', 'FG.pct',\n",
        "       '3P', '3PA', '3P.pct', '2P', '2PA', '2P.pct', 'eFG.pct', 'FT', 'FTA',\n",
        "       'FT.pct', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS',\n",
        "       'MP_Total', 'PER', 'TS.pct', '3PAr', 'FTr', 'ORB.pct', 'DRB.pct', 'TRB.pct',\n",
        "       'AST.pct', 'STL.pct', 'BLK.pct', 'TOV.pct', 'USG.pct', 'empty1', 'OWS',\n",
        "       'DWS', 'WS', 'WS/48', 'empty2', 'OBPM', 'DBPM', 'BPM', 'VORP']\n",
        "# drop columns with NA created with the scraping part\n",
        "stats_1718_full  = stats_1718_full.drop(['empty1', 'empty2'], axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xg6y8Gqhs1VT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creamos el fichero\n",
        "stats_1718_full.to_csv(\"full_stats_1718.csv\", index=False)\n",
        "\n",
        "# descargamos en formato .csv\n",
        "files.download(\"full_stats_1718.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yZtDMB-uFCc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}